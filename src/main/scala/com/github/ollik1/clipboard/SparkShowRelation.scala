package com.github.ollik1.clipboard

import org.apache.spark.rdd.RDD
import org.apache.spark.sql.sources.{BaseRelation, TableScan}
import org.apache.spark.sql.types.StructType
import org.apache.spark.sql.{Row, SQLContext}

/**
  * A relation for reading strings generated by [[org.apache.spark.sql.Dataset.show()]]
  *
  * An example string:
  * +----+----+
  * |foo |bar |
  * +----+----+
  * |   1|   a|
  * |   2|   b|
  * +----+----+
  *
  * - Lines starting with '+' are considered comments.
  * - Header is optional, default by true.
  * - Lines are stripped from leading and trailing pipes '|' and then the content is interpreted as CSV.
  */
class SparkShowRelation(
    override val sqlContext: SQLContext,
    parameters: Map[String, String],
    maybeSchema: Option[StructType]
) extends BaseRelation
    with TableScan {
  import sqlContext.implicits._

  val df = {
    val read = sqlContext.read

    maybeSchema.fold {
      read.option("inferSchema", "true")
    } {
      read.schema
    }

    read
      .option("header", parameters.getOrElse("header", "true"))
      .option("delimiter", "|")
      .option("ignoreLeadingWhiteSpace", "true")
      .option("ignoreTrailingWhiteSpace", "true")
      .option("comment", "+")
      .csv {
        sqlContext.read.textFile(parameters("path")).map { line =>
          line.trim.stripPrefix("|").stripSuffix("|")
        }
      }
  }

  override val schema: StructType = df.schema

  override def buildScan(): RDD[Row] = df.rdd
}
